{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import os, shutil, gdown, zipfile\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?export=download&id=19ZgvHREcc3SGYST_Nczl5XiHHgwvFPbp\n",
      "From (redirected): https://drive.google.com/uc?export=download&id=19ZgvHREcc3SGYST_Nczl5XiHHgwvFPbp&confirm=t&uuid=1604f5d9-c1ba-44bd-853f-0b036ad37234\n",
      "To: d:\\NextCloud\\github\\BigData-ML-Proyectos\\Trabajo Final\\downloaded_data\\dataset-xray.zip\n",
      "100%|██████████| 199M/199M [00:15<00:00, 13.0MB/s] \n",
      "[WinError 32] El proceso no tiene acceso al archivo porque está siendo utilizado por otro proceso: 'downloaded_data\\\\dataset-xray.zipqjf0kxeqtmp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga Completa!\n",
      "Extrayendo archivos...\n",
      "Datos extraidos!\n"
     ]
    }
   ],
   "source": [
    "# Crear directorio para almacenar los datos descargados\n",
    "download_dir = \"downloaded_data\"\n",
    "os.makedirs(download_dir, exist_ok = True)\n",
    "\n",
    "url = \"https://drive.google.com/uc?export=download&id=19ZgvHREcc3SGYST_Nczl5XiHHgwvFPbp\"\n",
    "output = download_dir + '/dataset-xray.zip'\n",
    "gdown.download(url, output , quiet = False)\n",
    "print(\"Descarga Completa!\")\n",
    "\n",
    "print(\"Extrayendo archivos...\")\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    # Extrae todos los archivos en el directorio de destino\n",
    "    zip_ref.extractall(download_dir)\n",
    "print(\"Datos extraidos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Cargando radiografias de COVID-19...\n",
      "Cargando radiografias de NEUMONIA...\n",
      "Cargando radiografias de NORMAL...\n",
      "Todos los datos cargados!\n"
     ]
    }
   ],
   "source": [
    "# Definir las categorías\n",
    "categories = [\"COVID-19\", \"NEUMONIA\", \"NORMAL\"]\n",
    "\n",
    "# Cargar datos de las carpetas extraídas\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "print(\"Cargando datos...\")\n",
    "for category in categories:\n",
    "    print(f\"Cargando radiografias de {category}...\")\n",
    "    for file in os.listdir(download_dir + \"/\" + category):\n",
    "        dir = download_dir + \"/\" + category + \"/\" + file\n",
    "        img = imread(dir, as_gray = True)\n",
    "        img = resize(img, (256, 256))\n",
    "        data.append(img.flatten())\n",
    "        label.append(categories.index(category))\n",
    "print(\"Todos los datos cargados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminando el directorio descargado...\n",
      "Directorio eliminado.\n"
     ]
    }
   ],
   "source": [
    "print(\"Eliminando el directorio descargado...\")\n",
    "shutil.rmtree(download_dir)\n",
    "print(\"Directorio eliminado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(data)\n",
    "label = np.asarray(label)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size = 0.2, shuffle = True, stratify = label, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'C': 15, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score: 0.9086984536082474\n"
     ]
    }
   ],
   "source": [
    "# Definimos un diccionario que especifica las combinaciones de hiperparámetros a explorar\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 15],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Creamos un modelo SVC\n",
    "grid_svc = SVC()\n",
    "\n",
    "# Creamos un objeto GridSearch para la busqueda de parametros y ajustamos a los datos de entrenamiento\n",
    "grid_search = GridSearchCV(grid_svc, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparametros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimimos el mejor modelo junto a su puntuacion\n",
    "print(\"Model:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
      "Best Score: 0.8505369415807561\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3,5,7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "grid_knn = KNeighborsClassifier()\n",
    "\n",
    "# Creamos un objeto GridSearch para la busqueda de parametros y ajustamos a los datos de entrenamiento\n",
    "grid_search = GridSearchCV(grid_knn, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparametros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimimos el mejor modelo junto a su puntuacion\n",
    "print(\"Model:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "540 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "330 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Martín\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68687715 0.71574313 0.68674828\n",
      " 0.71563574 0.73247423 0.72205756 0.70139605 0.74679983 0.71151203\n",
      " 0.71795533 0.68885309 0.68668385 0.74692869 0.67225086 0.71997423\n",
      " 0.64729381 0.72381873 0.72210052 0.72006014 0.72010309 0.69321306\n",
      " 0.70771048 0.69939863 0.70962199 0.73460052 0.72835052 0.71585052\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70551976 0.72218643 0.72830756\n",
      " 0.70955756 0.73457904 0.71161942 0.73638316 0.69284794 0.7304768\n",
      " 0.69512457 0.73659794 0.72190722 0.70139605 0.6970146  0.68051976\n",
      " 0.70549828 0.70740979 0.71365979 0.707689   0.71808419 0.70979381\n",
      " 0.71391753 0.71799828 0.695189   0.73045533 0.70753866 0.70560567\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74911942 0.71166237 0.72822165\n",
      " 0.7074957  0.69085052 0.71376718 0.71372423 0.75734536 0.72820017\n",
      " 0.69718643 0.70332904 0.72409794 0.71780498 0.6845146  0.67847938\n",
      " 0.73442869 0.69714347 0.69100086 0.7242268  0.71174828 0.70975086\n",
      " 0.71385309 0.7222079  0.69521048 0.71799828 0.70966495 0.70966495\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.69299828 0.71181271 0.71578608\n",
      " 0.71376718 0.7097079  0.72420533 0.73850945 0.69924828 0.75725945\n",
      " 0.66808419 0.70131014 0.64521048 0.7032646  0.68462199 0.74686426\n",
      " 0.69510309 0.69308419 0.68885309 0.71391753 0.70560567 0.72006014\n",
      " 0.68900344 0.70762457 0.71183419 0.69939863 0.72003866 0.70141753\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.72832904 0.75122423 0.68872423\n",
      " 0.70957904 0.73019759 0.73234536 0.72620275 0.72003866 0.73034794\n",
      " 0.69089347 0.68668385 0.72418385 0.69078608 0.68457904 0.66402491\n",
      " 0.69490979 0.72195017 0.68058419 0.72001718 0.71791237 0.707689\n",
      " 0.71174828 0.70352234 0.70156787 0.72837199 0.71582904 0.707689\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.71786942 0.73855241 0.74486684\n",
      " 0.74905498 0.72207904 0.72006014 0.74280498 0.72820017 0.73032646\n",
      " 0.69512457 0.68253866 0.73445017 0.70534794 0.69503866 0.68908935\n",
      " 0.68275344 0.69718643 0.70133162 0.73460052 0.71385309 0.71389605\n",
      " 0.71179124 0.707689   0.69933419 0.72837199 0.73247423 0.71997423\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.7532646  0.7220146  0.74682131\n",
      " 0.74688574 0.75721649 0.73026203 0.73664089 0.75324313 0.70962199\n",
      " 0.69308419 0.71589347 0.69110825 0.71372423 0.71786942 0.70551976\n",
      " 0.71585052 0.72195017 0.65786082 0.77613832 0.75747423 0.72622423\n",
      " 0.75322165 0.76782646 0.76363832 0.75118127 0.74293385 0.75524055\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74089347 0.72828608 0.70126718\n",
      " 0.72401203 0.72192869 0.73457904 0.73440722 0.76157646 0.74070017\n",
      " 0.75100945 0.68062715 0.71793385 0.66612973 0.68883162 0.72394759\n",
      " 0.73230241 0.66589347 0.71578608 0.75743127 0.74914089 0.74914089\n",
      " 0.73868127 0.75743127 0.75317869 0.74284794 0.74488832 0.74284794\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.70536942 0.74480241 0.73032646\n",
      " 0.73440722 0.74469502 0.75100945 0.72635309 0.74067869 0.74690722\n",
      " 0.70753866 0.7345146  0.69896907 0.71378866 0.70337199 0.65981529\n",
      " 0.70350086 0.69909794 0.72214347 0.75745275 0.73039089 0.75942869\n",
      " 0.77399055 0.75107388 0.75947165 0.74289089 0.73870275 0.75109536\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.71988832 0.74057131 0.72832904\n",
      " 0.75517612 0.74082904 0.7387457  0.7199957  0.72830756 0.71365979\n",
      " 0.71174828 0.68251718 0.70942869 0.70122423 0.7095146  0.69082904\n",
      " 0.73445017 0.71799828 0.68891753 0.74291237 0.76365979 0.75126718\n",
      " 0.75957904 0.76151203 0.77414089 0.74905498 0.74495275 0.74707904\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.75315722 0.75530498 0.75517612\n",
      " 0.73460052 0.73445017 0.72001718 0.70949313 0.71786942 0.73234536\n",
      " 0.71142612 0.73853093 0.72841495 0.71378866 0.73058419 0.70942869\n",
      " 0.70962199 0.67635309 0.67639605 0.72203608 0.74914089 0.77407646\n",
      " 0.76776203 0.7720146  0.74289089 0.75536942 0.74078608 0.73657646\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.71159794 0.70113832 0.72832904\n",
      " 0.76153351 0.75315722 0.75320017 0.71589347 0.75320017 0.75113832\n",
      " 0.67858677 0.68462199 0.72416237 0.72405498 0.69916237 0.7032646\n",
      " 0.72426976 0.68468643 0.68681271 0.76149055 0.74289089 0.7532646\n",
      " 0.74909794 0.75113832 0.73453608 0.73666237 0.74291237 0.74914089]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score: 0.7761383161512028\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Creamos un objeto GridSearch para la busqueda de parametros y ajustamos a los datos de entrenamiento\n",
    "grid_search = GridSearchCV(grid_dtc, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparametros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimimos el mejor modelo junto a su puntuacion\n",
    "print(\"Model:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'var_smoothing': 0.008111308307896872}\n",
      "Best Score: 0.7966924398625429\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "grid_gnb = GaussianNB()\n",
    "\n",
    "# Creamos un objeto GridSearch para la busqueda de parametros y ajustamos a los datos de entrenamiento\n",
    "grid_search = GridSearchCV(grid_gnb, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparametros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimimos el mejor modelo junto a su puntuacion\n",
    "print(\"Model:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: 0.8653135738831615\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_rtc = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Creamos un objeto GridSearch para la busqueda de parametros y ajustamos a los datos de entrenamiento\n",
    "grid_search = GridSearchCV(grid_rtc, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores hiperparametros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprimimos el mejor modelo junto a su puntuacion\n",
    "print(\"Model:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB Y MLP NO USADOS PQ TARDABAN MUCHO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
